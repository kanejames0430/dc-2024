{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.models import Range1d, Circle, MultiLine, ColorBar, LinearColorMapper, LogColorMapper\n",
    "from bokeh.models.layouts import TabPanel, Tabs\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.transform import linear_cmap, log_cmap\n",
    "from bokeh.palettes import Inferno256\n",
    "from bokeh.io import show, output_notebook\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from methods import (printProgressBar, build_graphs, build_plots, \n",
    "                     import_text, component_graphs, merge_datasets, tabbed_plot, \n",
    "                     plot_graph_bokeh, cleanList, get_sheetnames_xlsx,\n",
    "                     sortDict, plotVariablesByFreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for where your raw data is stored (.xlsx)\n",
    "RawDataPath = r'C:\\DC24_1\\dataset_1_original_combined'\n",
    "\n",
    "# Path for where your parsed data is stored (.json)\n",
    "ParsedDataPath = r'C:\\DC24_1\\dataset_parsed_combined'\n",
    "\n",
    "# Paths for where the media files reside\n",
    "audioPath = r'C:\\DC24_1\\audio'\n",
    "videoPath = r'C:\\DC24_1\\video'\n",
    "docsPath =  r'C:\\DC24_1\\doc'\n",
    "imagePath = r'C:\\DC24_1\\image'\n",
    "\n",
    "# Path for where you want your output data to be stored (.txt)\n",
    "dataOut = r'James_Code\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_30.xls is not the proper format (.xlsx). It is either corrupted or needs to be reformatted.\n",
      "file_652.xls is not the proper format (.xlsx). It is either corrupted or needs to be reformatted.\n",
      "file_711.xls is not the proper format (.xlsx). It is either corrupted or needs to be reformatted.\n",
      "Progress: |████████████████████████████████████████████████--| 97.9% Complete\r"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "xlsxDicionary = {}\n",
    "\n",
    "'''\n",
    "For every file in the specified location, try to obtain the sheet names. If the file is not of .xlsx format, \n",
    "then catch the error as it is either corrupted or needs to be reformatted (to be implemented later).\n",
    "Then update the dictionary\n",
    "'''\n",
    "\n",
    "l = len(os.listdir(RawDataPath))\n",
    "\n",
    "for p,fileName in enumerate(os.listdir(RawDataPath)):\n",
    "    filepath = RawDataPath + '/' + fileName\n",
    "\n",
    "    '''\n",
    "    We kept running into files that were either corrupt or .xls files, \n",
    "    so we just skipped over those files. Luckily, in this particular dataset,\n",
    "    there were only 3 files of this nature. This was also our reasoning to\n",
    "    pivot towards the parsed datasets.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        sheetnames = list(get_sheetnames_xlsx(filepath))\n",
    "    except:\n",
    "        print(fileName + \" is not the proper format (.xlsx). It is either corrupted or needs to be reformatted.\")\n",
    "    xlsxDicionary[fileName] = sheetnames\n",
    "    time.sleep(0.1)\n",
    "    printProgressBar(p+1, l ,prefix = 'Progress:', suffix = 'Complete', length = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the sheetnames within the excel file are plotted by the frequency that they appear in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots the type of data in the files by the frequency\n",
    "plotVariablesByFreq(xlsxDicionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Section:\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a temporary list, and a master dictionary\n",
    "audioList = []\n",
    "masterDictAudio = {}\n",
    "\n",
    "#for progress bar\n",
    "l = len(os.listdir(ParsedDataPath))\n",
    "printProgressBar(0,l,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Each .json file in the path represents a device, we need to navigate to the Audio files stored on the device, and collect all the MD5 hash values\n",
    "for j,file in enumerate(os.listdir(ParsedDataPath)):\n",
    "    hashList = []\n",
    "    with open(ParsedDataPath + '/' + file) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    for item in json_data:\n",
    "        if item.get('Audio'): \n",
    "            audioList = (item.get('Audio'))\n",
    "            for i in range (len(audioList)):\n",
    "                if audioList[i].get('md5'):\n",
    "                    hashList.append(audioList[i].get('md5'))\n",
    "                masterDictAudio[(json_file.name).split('/')[-1]] = cleanList(hashList)\n",
    "    \n",
    "    #part of progress bar graphic\n",
    "    time.sleep(0.1)\n",
    "    printProgressBar(j+1, l ,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "#write the audio master dictionary data to .txt file for later use\n",
    "with open(r'data/audiologs.txt','w+') as f:\n",
    "    f.write(str(masterDictAudio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "Audiomd5 = {}\n",
    "\n",
    "'''\n",
    " We have a folder full of audio files. The names of the files may not be helpful for linking devices together as users \n",
    " can easily change the names of files independently. Instead, we will look at the MD5 hash values of the each file.\n",
    "'''\n",
    "\n",
    "#for each file in the audio folder, get the MD5 hash value and append it to the dictionary respective to the file name.\n",
    "for thing in os.listdir(audioPath):\n",
    "\n",
    "    #calculates the MD5 hash of the given file. md5 is a dictionary of format {'audio file name' : ['MD5 Hash value']}\n",
    "    Audiomd5[thing] = [hashlib.md5(open(audioPath + '/' + thing,'rb').read()).hexdigest()]\n",
    "\n",
    "#write the md5 data to .txt file for later use\n",
    "with open(r'data/AudioMD5logs.txt','w+',encoding='utf-8') as f:\n",
    "    f.write(str(Audiomd5))\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "datasetsAudio = {}\n",
    "datasetsAudio['Audio to MD5'] = (import_text(r'data/AudioMD5logs.txt'))\n",
    "datasetsAudio['All MD5'] = (import_text(r'data/audiologs.txt'))\n",
    "\n",
    "# Finds the common MD5 hash values bewteen the ones we calculated, and the ones that were found in the dataset\n",
    "# Creates a list of the hash values from our audio file folder\n",
    "hashVal = list(datasetsAudio['Audio to MD5'].values())\n",
    "deviceWithPosMD5 = {}\n",
    "\n",
    "#for all the MD5 values in the dataset, and for all calculated hash values, if the calculated hash value exists in the dataset, \n",
    "#   append to a list that correlates with the given file name in dictionary\n",
    "# deviceWithPosMD5 has format {'.json file name' : [list of matched/common MD5 values]}\n",
    "for k,m in datasetsAudio['All MD5'].items():\n",
    "    tempList = []\n",
    "    for val in hashVal:\n",
    "        tempString = str(val)\n",
    "        tempString = tempString.strip(\"]\").strip(\"'\").strip(\"[\").strip(\"'\")\n",
    "        if tempString in m:\n",
    "            tempList.append((tempString))\n",
    "        deviceWithPosMD5[k] = tempList \n",
    "\n",
    "#write the deviceWithPosMD5 data to .txt file for later use\n",
    "with open(r'data/devWithPosAudioMD5.txt','w+') as f:\n",
    "    f.write(str(deviceWithPosMD5))\n",
    "\n",
    "\n",
    "'''\n",
    "When we draw the graphs, Devices with MD5 with no links attached represent devices (or .json files) with no common MD5 hash values.\n",
    "\n",
    "Our Audio to MD5 graph will just link audio file names to their calculated MD5 hash value.\n",
    "\n",
    "The merged graph draws both prior graphs onto 1 pane and connects common nodes.\n",
    "'''\n",
    "\n",
    "#initialize a new diciontary for drawing the graphs. All we care about are the files/devices that share MD5 hash values with our audio files \n",
    "finalDatasetAudio = {}\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "finalDatasetAudio['Devices with MD5'] = (import_text(r'data/devWithPosAudioMD5.txt'))\n",
    "finalDatasetAudio['Audio file -> MD5'] = (import_text(r'data/AudioMD5logs.txt'))\n",
    "\n",
    "# Merge the dictionaries into one\n",
    "finalDatasetAudio['merged'] = merge_datasets(finalDatasetAudio['Audio file -> MD5'], finalDatasetAudio['Devices with MD5'])\n",
    "\n",
    "# Generating networkx graphs for each dataset\n",
    "graphsAudio = build_graphs(finalDatasetAudio)\n",
    "build_plots(graphsAudio)\n",
    "\n",
    "# Calculate the 8 largest components. The 9th largest becomes just 1 link between 2 nodes\n",
    "components = component_graphs(graphsAudio['merged'], components_selection=9)\n",
    "node_highlights = finalDatasetAudio['merged'].keys()\n",
    "\n",
    "output_notebook()\n",
    " \n",
    "plot = figure(title='Update Example', x_axis_label='Time', y_axis_label='Value')\n",
    "line = plot.line([], [])\n",
    "handle = show(tabbed_plot(finalDatasetAudio['Devices with MD5'],components, node_highlights=node_highlights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Section:\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lists, masterDict, and path\n",
    "videoList = []\n",
    "masterDictVideo = {}\n",
    "\n",
    "\n",
    "l = len(os.listdir(ParsedDataPath))\n",
    "printProgressBar(0,l,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Each .json file in the path represents a device, we need to navigate to the video files stored on the device, and collect all the MD5 hash values\n",
    "for j,file in enumerate(os.listdir(ParsedDataPath)):\n",
    "    hashList = []\n",
    "    with open(ParsedDataPath + '/' + file) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    for item in json_data:\n",
    "        if item.get('Videos'): \n",
    "            videoList = (item.get('Videos'))\n",
    "            for i in range (len(videoList)):\n",
    "                if videoList[i].get('md5'):\n",
    "                    hashList.append(videoList[i].get('md5'))\n",
    "                masterDictVideo[(json_file.name).split('/')[-1]] = cleanList(hashList)\n",
    "    \n",
    "    #part of progress bar graphic\n",
    "    time.sleep(0.1)\n",
    "    printProgressBar(j+1, l ,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "#write the masterDict data to .txt file for later use\n",
    "with open(r'data/videologs.txt','w+') as f:\n",
    "    f.write(str(masterDictVideo))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "md5Video = {}\n",
    "\n",
    "# We have a folder full of video files. The names of the files may not be helpful for linking devices together as users \n",
    "#   can easily change the names of files independently. Instead, we will look at the MD5 hash values of the each file.\n",
    "#for each file in the video folder, get the MD5 hash value and append it to the dictionary respective to the file name.\n",
    "for y in os.listdir(videoPath):\n",
    "\n",
    "    #calculates the MD5 hash of the given file. md5 is a dictionary of format {'video file name' : ['MD5 Hash value']}\n",
    "    md5Video[y] = [hashlib.md5(open(videoPath + '/' + y,'rb').read()).hexdigest()]\n",
    "\n",
    "#write the md5 data to .txt file for later use\n",
    "with open(r'data/VideoMD5logs.txt','w+',encoding='utf-8') as f:\n",
    "    f.write(str(md5Video))\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "datasetsVideo = {}\n",
    "datasetsVideo['Video to MD5'] = (import_text(r'data/VideoMD5logs.txt'))\n",
    "datasetsVideo['All MD5'] = (import_text(r'data/videologs.txt'))\n",
    "\n",
    "# Creates a list of the hash values from our video file folder\n",
    "hashVal = list(datasetsVideo['Video to MD5'].values())\n",
    "deviceWithPosMD5 = {}\n",
    "\n",
    "#for all the MD5 values in the dataset, and for all calculated hash values, if the calculated hash value exists in the dataset, \n",
    "#   append to a list that correlates with the given file name in dictionary\n",
    "# deviceWithPosMD5 has format {'.json file name' : [list of matched/common MD5 values]}\n",
    "for k,m in datasetsVideo['All MD5'].items():\n",
    "    tempList = []\n",
    "    for val in hashVal:\n",
    "        tempString = str(val)\n",
    "        tempString = tempString.strip(\"]\").strip(\"'\").strip(\"[\").strip(\"'\")\n",
    "        if tempString in m:\n",
    "            tempList.append((tempString))\n",
    "        deviceWithPosMD5[k] = tempList \n",
    "\n",
    "#write the deviceWithPosMD5 data to .txt file for later use\n",
    "with open(r'data/devWithPosVideoMD5.txt','w+') as f:\n",
    "    f.write(str(deviceWithPosMD5))\n",
    "\n",
    "#Intialize\n",
    "finalDatasetVideo = {}\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "finalDatasetVideo['Devices with MD5'] = (import_text(r'data/devWithPosVideoMD5.txt'))\n",
    "finalDatasetVideo['Video file -> MD5'] = (import_text(r'data/VideoMD5logs.txt'))\n",
    "\n",
    "# Merge the dictionaries into one\n",
    "finalDatasetVideo['merged'] = merge_datasets(finalDatasetVideo['Video file -> MD5'], finalDatasetVideo['Devices with MD5'])\n",
    "\n",
    "# Generating networkx graphs for each dataset\n",
    "graphsVideo = build_graphs(finalDatasetVideo)\n",
    "build_plots(graphsVideo)\n",
    "\n",
    "# Calculate the 8 largest components. The 9th largest becomes just 1 link between 2 nodes\n",
    "components = component_graphs(graphsVideo['merged'], components_selection=10)\n",
    "node_highlights = finalDatasetVideo['merged'].keys()\n",
    "\n",
    "output_notebook()\n",
    " \n",
    "plot = figure(title='Update Example', x_axis_label='Time', y_axis_label='Value')\n",
    "line = plot.line([], [])\n",
    "handle = show(tabbed_plot(finalDatasetVideo['Devices with MD5'], components, node_highlights=node_highlights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged audio and video graphs:\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets (Audio and Video) into one.\n",
    "masterDataDict = {}\n",
    "\n",
    "masterDataDict['Audio'] = finalDatasetAudio['merged']\n",
    "masterDataDict['Video'] = finalDatasetVideo['merged']\n",
    "masterDataDict['Audio and Video'] = merge_datasets(masterDataDict['Audio'],masterDataDict['Video'])\n",
    "\n",
    "#this is just a reorganization of the dictionaries for the tabbed_plot() function\n",
    "posMD5Dict = merge_datasets(finalDatasetVideo['Devices with MD5'],finalDatasetAudio['Devices with MD5'])\n",
    "\n",
    "graphsMaster = build_graphs(masterDataDict)\n",
    "build_plots(graphsMaster)\n",
    "\n",
    "# Calculate the 8 largest components. The 9th largest becomes just 1 link between 2 nodes\n",
    "components = component_graphs(graphsMaster['Audio and Video'], components_selection=10)\n",
    "node_highlights = masterDataDict['Audio and Video'].keys()\n",
    "\n",
    "output_notebook()\n",
    " \n",
    "plot = figure(title='Update Example', x_axis_label='Time', y_axis_label='Value')\n",
    "line = plot.line([], [])\n",
    "handle = show(tabbed_plot(posMD5Dict, components, node_highlights=node_highlights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documents Section:\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lists, masterDict, and path\n",
    "docsList = []\n",
    "masterDictDocs = {}\n",
    "\n",
    "\n",
    "l = len(os.listdir(ParsedDataPath))\n",
    "printProgressBar(0,l,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "# Each .json file in the path represents a device, we need to navigate to the docs files stored on the device, and collect all the MD5 hash values\n",
    "for j,file in enumerate(os.listdir(ParsedDataPath)):\n",
    "    hashList = []\n",
    "    with open(ParsedDataPath + '/' + file) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    for item in json_data:\n",
    "        if item.get('Document'): \n",
    "            docsList = (item.get('Document'))\n",
    "            for i in range (len(docsList)):\n",
    "                if docsList[i].get('md5'):\n",
    "                    hashList.append(docsList[i].get('md5'))\n",
    "                masterDictDocs[(json_file.name).split('/')[-1]] = cleanList(hashList)\n",
    "    \n",
    "    #part of progress bar graphic\n",
    "    time.sleep(0.1)\n",
    "    printProgressBar(j+1, l ,prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "#write the masterDict data to .txt file for later use\n",
    "with open(r'data/docslogs.txt','w+') as f:\n",
    "    f.write(str(masterDictDocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize\n",
    "md5Docs = {}\n",
    "\n",
    "# We have a folder full of docs files. The names of the files may not be helpful for linking devices together as users \n",
    "#   can easily change the names of files independently. Instead, we will look at the MD5 hash values of the each file.\n",
    "\n",
    "#for each file in the docs folder, get the MD5 hash value and append it to the dictionary respective to the file name.\n",
    "for y in os.listdir(docsPath):\n",
    "\n",
    "    #calculates the MD5 hash of the given file. md5 is a dictionary of format {'docs file name' : ['MD5 Hash value']}\n",
    "    md5Docs[y] = [hashlib.md5(open(docsPath + '/' + y,'rb').read()).hexdigest()]\n",
    "\n",
    "#write the md5 data to .txt file for later use\n",
    "with open(r'data/DocsMD5logs.txt','w+',encoding='utf-8') as f:\n",
    "    f.write(str(md5Docs))\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "datasetsDocs = {}\n",
    "datasetsDocs['Docs to MD5'] = (import_text(r'data/DocsMD5logs.txt'))\n",
    "datasetsDocs['All MD5'] = (import_text(r'data/docslogs.txt'))\n",
    "\n",
    "# Creates a list of the hash values from our docs file folder\n",
    "hashVal = list(datasetsDocs['Docs to MD5'].values())\n",
    "deviceWithPosMD5 = {}\n",
    "\n",
    "#for all the MD5 values in the dataset, and for all calculated hash values, if the calculated hash value exists in the dataset, \n",
    "#   append to a list that correlates with the given file name in dictionary\n",
    "# deviceWithPosMD5 has format {'.json file name' : [list of matched/common MD5 values]}\n",
    "for k,m in datasetsDocs['All MD5'].items():\n",
    "    tempList = []\n",
    "    for val in hashVal:\n",
    "        tempString = str(val)\n",
    "        tempString = tempString.strip(\"]\").strip(\"'\").strip(\"[\").strip(\"'\")\n",
    "        if tempString in m:\n",
    "            tempList.append((tempString))\n",
    "        deviceWithPosMD5[k] = tempList \n",
    "\n",
    "#write the deviceWithPosMD5 data to .txt file for later use\n",
    "with open(r'data/devWithPosDocsMD5.txt','w+', encoding=\"utf-8\") as f:\n",
    "    f.write(str(deviceWithPosMD5))\n",
    "\n",
    "#Intialize\n",
    "finalDatasetDocs = {}\n",
    "\n",
    "# Importing datasets from .txt files\n",
    "finalDatasetDocs['Devices with MD5'] = (import_text(r'data/devWithPosDocsMD5.txt'))\n",
    "finalDatasetDocs['Docs file -> MD5'] = (import_text(r'data/DocsMD5logs.txt'))\n",
    "\n",
    "# Merge the dictionaries into one\n",
    "finalDatasetDocs['merged'] = merge_datasets(finalDatasetDocs['Docs file -> MD5'], finalDatasetDocs['Devices with MD5'])\n",
    "\n",
    "# Generating networkx graphs for each dataset\n",
    "graphsDocs = build_graphs(finalDatasetDocs)\n",
    "build_plots(graphsDocs)\n",
    "\n",
    "# Calculate the 8 largest components. The 9th largest becomes just 1 link between 2 nodes\n",
    "components = component_graphs(graphsDocs['merged'], components_selection=5)\n",
    "node_highlights = finalDatasetDocs['merged'].keys()\n",
    "\n",
    "output_notebook()\n",
    " \n",
    "plot = figure(title='Update Example', x_axis_label='Time', y_axis_label='Value')\n",
    "line = plot.line([], [])\n",
    "handle = show(tabbed_plot(finalDatasetDocs['Devices with MD5'], components, node_highlights=node_highlights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
